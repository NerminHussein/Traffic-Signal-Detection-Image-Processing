{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAxbZvU1XhUdO+oLh9fCKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NerminHussein/Traffic-Signal-Detection-Image-Processing/blob/master/trafficSignTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iRFus8xufJw_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras,os\n",
        "import keras as model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "h2xj3N0BK8oZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n"
      ],
      "metadata": {
        "id": "gGzKrliMMP0n"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "from PIL import Image\n",
        "\n",
        "def videoToFrames(fileName):\n",
        "    vidcap = cv2.VideoCapture(fileName)\n",
        "    success,image = vidcap.read()\n",
        "    count = 0\n",
        "    images=[]\n",
        "    while success:\n",
        "        if count %1 ==0:\n",
        "            images.append(image)\n",
        "        success,image = vidcap.read()\n",
        "        count += 1\n",
        "    return images;\n",
        "\n",
        "\n",
        "def load_images_from_video_folder(folder,lable):\n",
        "    dataset=[]    \n",
        "    for filename in os.listdir(folder):\n",
        "        images=videoToFrames(os.path.join(folder,filename)) \n",
        "        im=[]\n",
        "        c=1\n",
        "        for img in images:\n",
        "            n_img=cv2.resize(img,(150,150))\n",
        "          \n",
        "            if img is not None :\n",
        "                im.append(n_img)\n",
        "          \n",
        "            if c % 1 == 0:\n",
        "                image=[]\n",
        "\n",
        "               \n",
        "                image.append(im)\n",
        "                image.append(lable)\n",
        "                im=[]\n",
        "                dataset.append(image)\n",
        "                c=0\n",
        "          \n",
        "            c=c+1\n",
        "        \n",
        "        if len(im)!=0:\n",
        "            print(len(im),filename)\n",
        "    return dataset\n",
        "\n",
        "def saveModel(Value, FileName):\n",
        "    file=open(FileName,\"wb\")\n",
        "    pickle.dump(Value,file)\n",
        "    file.close()\n",
        "\n",
        "\n",
        "\n",
        "#take care about using load_images_from_**video**_folder\n",
        "def preprocessDataset(sign,nonsign,outXFile,outYFile):\n",
        "\n",
        "   \n",
        "    dataset=load_images_from_video_folder(sign ,1)\n",
        "    dataset+=load_images_from_video_folder(nonsign,0)\n",
        "\n",
        "    print(len(dataset))\n",
        "\n",
        "    random.shuffle(dataset)\n",
        "    \n",
        "    x=[]\n",
        "    y=[]\n",
        "    \n",
        "    while len(dataset)!=0 :\n",
        "        img,label = dataset.pop()\n",
        "        x.append(img)\n",
        "        y.append(label)\n",
        "\n",
        "    y= np.array(y).reshape(-1,1)\n",
        "    x= np.array(x).reshape(-1,1,150,150,3)\n",
        "    \n",
        "    saveModel(x,outXFile)\n",
        "    saveModel(y,outYFile)\n",
        "\n",
        "    return x[1],y[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "imgs ,labels=preprocessDataset('/content/nonsign/',\n",
        "                  '/content/sign/',\n",
        "                  'all_X_avg_5.pkl',\n",
        "                  'all_Y_avg_5.pkl')\n",
        "\n",
        "plt.imshow(imgs[0][0])\n",
        "plt.show()\n",
        "\n",
        "data =[]\n",
        "\n",
        "#for img in imgs:\n",
        "   # try:\n",
        "        #image = cv2.imread(img)\n",
        "        #data.append(np.array(img))\n",
        "    #except:\n",
        "       #print(\"Error in \" + img)\n",
        "\n",
        "X_test = np.array(imgs)\n",
        "model2=keras.models.load_model('modelGTSRB-1.h5')\n",
        "pred=model2.predict(X_test) \n",
        "classes_x=np.argmax(pred,axis=1)\n",
        "#classes_x=np.argmax(predict_x,axis=1)\n",
        "\n",
        "#Accuracy with the test data\n",
        "print('Test Data accuracy: ',accuracy_score(labels, classes_x)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "lJdqa9xzTT9w",
        "outputId": "3fa53db1-4b53-4ea0-953a-3379745bb302"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Data accuracy:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dvSZBt9KTTJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#per image IMG_HEIGHT = 30 ,IMG_WIDTH = 30 ,channels = 3\n",
        "cap = cv2.VideoCapture('REC1.mp4')\n"
      ],
      "metadata": {
        "id": "PsykSgekNQ2D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HbEo2pgbNcHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=keras.models.load_model('modelGTSRB-1.h5')"
      ],
      "metadata": {
        "id": "X6BU20XJLZL4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "imgs = x\n",
        "labels = y\n",
        "\n",
        "data =[]\n",
        "\n",
        "for img in imgs:\n",
        "    try:\n",
        "        image = cv2.imread(img)\n",
        "        image_fromarray = Image.fromarray(image, 'RGB')\n",
        "        resize_image = image_fromarray.resize((30, 30))\n",
        "        data.append(np.array(resize_image))\n",
        "    except:\n",
        "        print(\"Error in \" + img)\n",
        "X_test = np.array(data)\n",
        "\n",
        "\n",
        "#pred = model.predict_classes(X_test)\n",
        "pred=model2.predict(X_test) \n",
        "classes_x=np.argmax(pred,axis=1)\n",
        "#classes_x=np.argmax(predict_x,axis=1)\n",
        "\n",
        "#Accuracy with the test data\n",
        "print('Test Data accuracy: ',accuracy_score(labels, classes_x)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "1_qcRh3CLRTV",
        "outputId": "db0639fc-5731-40bc-b71f-232debbc936d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in /\n",
            "Error in c\n",
            "Error in o\n",
            "Error in n\n",
            "Error in t\n",
            "Error in e\n",
            "Error in n\n",
            "Error in t\n",
            "Error in /\n",
            "Error in a\n",
            "Error in l\n",
            "Error in l\n",
            "Error in _\n",
            "Error in X\n",
            "Error in _\n",
            "Error in a\n",
            "Error in v\n",
            "Error in g\n",
            "Error in _\n",
            "Error in 5\n",
            "Error in .\n",
            "Error in p\n",
            "Error in k\n",
            "Error in l\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5fa692e5c643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#pred = model.predict_classes(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mclasses_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#classes_x=np.argmax(predict_x,axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m         raise ValueError('Unexpected result of `predict_function` '\n\u001b[0m\u001b[1;32m   1998\u001b[0m                          \u001b[0;34m'(Empty batch_outputs). Please use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m                          \u001b[0;34m'`Model.compile(..., run_eagerly=True)`, or '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ucfuoqFHcg_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}